{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x12d3fe1d0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from string import punctuation\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "torch.manual_seed(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Instructions\n",
    "\n",
    "- You need to download the dataset from here: https://ai.stanford.edu/~amaas/data/sentiment/\n",
    "- Then, you need to unzip the downloaded zipped file in the present working directory\n",
    "- That should result in a new folder named aclImdb under the present working directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12500/12500 [00:04<00:00, 2903.14it/s]\n",
      "100%|██████████| 12500/12500 [00:04<00:00, 2929.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of reviews : 25000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# read sentiments and reviews data from the text files\n",
    "review_list = []\n",
    "label_list = []\n",
    "for label in ['pos', 'neg']:\n",
    "    for fname in tqdm(os.listdir(f'./aclImdb/train/{label}/')):\n",
    "        if 'txt' not in fname:\n",
    "            continue\n",
    "        with open(os.path.join(f'./aclImdb/train/{label}/', fname), encoding=\"utf8\") as f:\n",
    "            review_list += [f.read()]\n",
    "            label_list += [label]\n",
    "print ('Number of reviews :', len(review_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'for a movie that gets no respect there sure are a lot of memorable quotes listed for this gem imagine a movie where joe piscopo is actually funny maureen stapleton is a scene stealer the moroni character is an absolute scream watch for alan the skipper hale jr as a police sgt'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_list[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get word counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25000/25000 [00:01<00:00, 12899.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 334691), ('and', 162228), ('a', 161940), ('of', 145326), ('to', 135042), ('is', 106855), ('in', 93028), ('it', 77099), ('i', 75719), ('this', 75190)]\n"
     ]
    }
   ],
   "source": [
    "# pre-processing review text\n",
    "review_list = [review.lower() for review in review_list]\n",
    "review_list = [''.join([letter for letter in review if letter not in punctuation]) for review in tqdm(review_list)]\n",
    "\n",
    "# accumulate all review texts together\n",
    "reviews_blob = ' '.join(review_list)\n",
    "\n",
    "# generate list of all words of all reviews\n",
    "review_words = reviews_blob.split()\n",
    "\n",
    "# get the word counts\n",
    "count_words = Counter(review_words)\n",
    "\n",
    "# sort words as per counts (decreasing order)\n",
    "total_review_words = len(review_words)\n",
    "sorted_review_words = count_words.most_common(total_review_words)\n",
    "\n",
    "print(sorted_review_words[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generate word tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 1), ('and', 2), ('a', 3), ('of', 4), ('to', 5), ('is', 6), ('in', 7), ('it', 8), ('i', 9), ('this', 10)]\n"
     ]
    }
   ],
   "source": [
    "# create word to integer (token) dictionary in order to encode text as numbers\n",
    "vocab_to_token = {word:idx+1 for idx, (word, count) in enumerate(sorted_review_words)}\n",
    "print(list(vocab_to_token.items())[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tokenize text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for a movie that gets no respect there sure are a lot of memorable quotes listed for this gem imagine a movie where joe piscopo is actually funny maureen stapleton is a scene stealer the moroni character is an absolute scream watch for alan the skipper hale jr as a police sgt\n",
      "\n",
      "[15, 3, 17, 11, 201, 56, 1165, 47, 242, 23, 3, 168, 4, 891, 4325, 3513, 15, 10, 1514, 822, 3, 17, 112, 884, 14623, 6, 155, 161, 7307, 15816, 6, 3, 134, 20049, 1, 32064, 108, 6, 33, 1492, 1943, 103, 15, 1550, 1, 18993, 9055, 1809, 14, 3, 549, 6906]\n"
     ]
    }
   ],
   "source": [
    "reviews_tokenized = []\n",
    "for review in review_list:\n",
    "    word_to_token = [vocab_to_token[word] for word in review.split()]\n",
    "    reviews_tokenized.append(word_to_token)\n",
    "print(review_list[0])\n",
    "print()\n",
    "print (reviews_tokenized[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'for a movie that gets no respect there sure are a lot of memorable quotes listed for this gem imagine a movie where joe piscopo is actually funny maureen stapleton is a scene stealer the moroni character is an absolute scream watch for alan the skipper hale jr as a police sgt'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bizarre horror movie filled with famous faces but stolen by cristina raines later of tvs flamingo road as a pretty but somewhat unstable model with a gummy smile who is slated to pay for her attempted suicides by guarding the gateway to hell the scenes with raines modeling are very well captured the mood music is perfect deborah raffin is charming as cristinas pal but when raines moves into a creepy brooklyn heights brownstone inhabited by a blind priest on the top floor things really start cooking the neighbors including a fantastically wicked burgess meredith and kinky couple sylvia miles  beverly dangelo are a diabolical lot and eli wallach is great fun as a wily police detective the movie is nearly a crosspollination of rosemarys baby and the exorcistbut what a combination based on the bestseller by jeffrey konvitz the sentinel is entertainingly spooky full of shocks brought off well by director michael winner who mounts a thoughtfully downbeat ending with skill 12 from '"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_list[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tokenize output labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode sentiments as 0 or 1\n",
    "encoded_label_list = [1 if label =='pos' else 0 for label in label_list]\n",
    "\n",
    "reviews_len = [len(review) for review in reviews_tokenized]\n",
    "\n",
    "reviews_tokenized = [reviews_tokenized[i] for i, l in enumerate(reviews_len) if l>0 ]\n",
    "encoded_label_list = np.array([encoded_label_list[i] for i, l in enumerate(reviews_len) if l> 0 ], dtype='float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pad text sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def pad_sequence(reviews_tokenized, sequence_length):\n",
    "    ''' returns the tokenized review sequences padded with 0's or truncated to the sequence_length.\n",
    "    '''\n",
    "    padded_reviews = np.zeros((len(reviews_tokenized), sequence_length), dtype = int)\n",
    "    \n",
    "    for idx, review in enumerate(reviews_tokenized):\n",
    "        review_len = len(review)\n",
    "        \n",
    "        if review_len <= sequence_length:\n",
    "            zeroes = list(np.zeros(sequence_length-review_len))\n",
    "            new_sequence = zeroes+review\n",
    "        elif review_len > sequence_length:\n",
    "            new_sequence = review[0:sequence_length]\n",
    "        \n",
    "        padded_reviews[idx,:] = np.array(new_sequence)\n",
    "    \n",
    "    return padded_reviews\n",
    "\n",
    "sequence_length = 512\n",
    "padded_reviews = pad_sequence(reviews_tokenized=reviews_tokenized, sequence_length=sequence_length)\n",
    "\n",
    "plt.hist(reviews_len);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### split dataset to training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_split = 0.75\n",
    "train_X = padded_reviews[:int(train_val_split*len(padded_reviews))]\n",
    "train_y = encoded_label_list[:int(train_val_split*len(padded_reviews))]\n",
    "validation_X = padded_reviews[int(train_val_split*len(padded_reviews)):]\n",
    "validation_y = encoded_label_list[int(train_val_split*len(padded_reviews)):]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(torch.from_numpy(train_X).to(device), torch.from_numpy(train_y).to(device))\n",
    "validation_dataset = TensorDataset(torch.from_numpy(validation_X).to(device), torch.from_numpy(validation_y).to(device))\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "validation_dataloader = DataLoader(validation_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualise data samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example Input size:  torch.Size([32, 512])\n",
      "Example Input:\n",
      " tensor([[   0,    0,    0,  ...,  342,   23,  868],\n",
      "        [   0,    0,    0,  ..., 6242,   12, 2872],\n",
      "        [   0,    0,    0,  ...,   11,  105, 3490],\n",
      "        ...,\n",
      "        [   0,    0,    0,  ...,   42,    1,   17],\n",
      "        [  48,   81,   22,  ..., 1141,   32,  105],\n",
      "        [   0,    0,    0,  ...,  373,  150,  121]])\n",
      "\n",
      "Example Output size:  torch.Size([32])\n",
      "Example Output:\n",
      " tensor([0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,\n",
      "        1., 0., 0., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1.])\n"
     ]
    }
   ],
   "source": [
    "# get a batch of train data\n",
    "train_data_iter = iter(train_dataloader)\n",
    "X_example, y_example = train_data_iter.next()\n",
    "print('Example Input size: ', X_example.size()) # batch_size, seq_length\n",
    "print('Example Input:\\n', X_example)\n",
    "print()\n",
    "print('Example Output size: ', y_example.size()) # batch_size\n",
    "print('Example Output:\\n', y_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define and instantiate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_dimension, embedding_dimension, hidden_dimension, output_dimension):\n",
    "        super().__init__()\n",
    "        self.embedding_layer = nn.Embedding(input_dimension, embedding_dimension)  \n",
    "        self.rnn_layer = nn.RNN(embedding_dimension, hidden_dimension, num_layers=1)\n",
    "        self.fc_layer = nn.Linear(hidden_dimension, output_dimension)\n",
    "        \n",
    "    def forward(self, sequence):\n",
    "        # sequence shape = (sequence_length, batch_size)\n",
    "        embedding = self.embedding_layer(sequence)  \n",
    "        # embedding shape = [sequence_length, batch_size, embedding_dimension]\n",
    "        output, hidden_state = self.rnn_layer(embedding)\n",
    "        # output shape = [sequence_length, batch_size, hidden_dimension]\n",
    "        # hidden_state shape = [1, batch_size, hidden_dimension]\n",
    "        final_output = self.fc_layer(hidden_state[-1,:,:].squeeze(0))      \n",
    "        return final_output\n",
    "    \n",
    "input_dimension = len(vocab_to_token)+1 # +1 to account for padding\n",
    "embedding_dimension = 100\n",
    "hidden_dimension = 32\n",
    "output_dimension = 1\n",
    "\n",
    "rnn_model = RNN(input_dimension, embedding_dimension, hidden_dimension, output_dimension)\n",
    "\n",
    "optim = torch.optim.Adam(rnn_model.parameters())\n",
    "loss_func = nn.BCEWithLogitsLoss()\n",
    "\n",
    "rnn_model = rnn_model.to(device)\n",
    "loss_func = loss_func.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the model training and validation routines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_metric(predictions, ground_truth):\n",
    "    \"\"\"\n",
    "    Returns 0-1 accuracy for the given set of predictions and ground truth\n",
    "    \"\"\"\n",
    "    # round predictions to either 0 or 1\n",
    "    rounded_predictions = torch.round(torch.sigmoid(predictions))\n",
    "    success = (rounded_predictions == ground_truth).float() #convert into float for division \n",
    "    accuracy = success.sum() / len(success)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader, optim, loss_func):\n",
    "    loss = 0\n",
    "    accuracy = 0\n",
    "    model.train()\n",
    "    \n",
    "    for sequence, sentiment in dataloader:\n",
    "        optim.zero_grad()     \n",
    "        preds = model(sequence.T).squeeze()\n",
    "        \n",
    "        loss_curr = loss_func(preds, sentiment)\n",
    "        accuracy_curr = accuracy_metric(preds, sentiment)\n",
    "        \n",
    "        loss_curr.backward()\n",
    "        optim.step()\n",
    "        \n",
    "        loss += loss_curr.item()\n",
    "        accuracy += accuracy_curr.item()\n",
    "        \n",
    "    return loss/len(dataloader), accuracy/len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, dataloader, loss_func):\n",
    "    loss = 0\n",
    "    accuracy = 0\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for sequence, sentiment in dataloader:\n",
    "            \n",
    "            preds = model(sequence.T).squeeze()\n",
    "            \n",
    "            loss_curr = loss_func(preds, sentiment)   \n",
    "            accuracy_curr = accuracy_metric(preds, sentiment)\n",
    "\n",
    "            loss += loss_curr.item()\n",
    "            accuracy += accuracy_curr.item()\n",
    "        \n",
    "    return loss/len(dataloader), accuracy/len(dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the model training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number: 1 | time elapsed: 98.8182909488678s\n",
      "training loss: 0.623 | training accuracy: 66.50%\n",
      "validation loss: 0.867 |  validation accuracy: 42.10%\n",
      "\n",
      "epoch number: 2 | time elapsed: 99.33515810966492s\n",
      "training loss: 0.528 | training accuracy: 74.30%\n",
      "validation loss: 0.777 |  validation accuracy: 56.33%\n",
      "\n",
      "epoch number: 3 | time elapsed: 104.88390898704529s\n",
      "training loss: 0.446 | training accuracy: 79.67%\n",
      "validation loss: 0.854 |  validation accuracy: 55.93%\n",
      "\n",
      "epoch number: 4 | time elapsed: 103.1292142868042s\n",
      "training loss: 0.363 | training accuracy: 84.82%\n",
      "validation loss: 0.925 |  validation accuracy: 56.73%\n",
      "\n",
      "epoch number: 5 | time elapsed: 105.07887625694275s\n",
      "training loss: 0.289 | training accuracy: 88.72%\n",
      "validation loss: 1.444 |  validation accuracy: 41.83%\n",
      "\n",
      "epoch number: 6 | time elapsed: 118.14540910720825s\n",
      "training loss: 0.271 | training accuracy: 89.64%\n",
      "validation loss: 0.895 |  validation accuracy: 58.15%\n",
      "\n",
      "epoch number: 7 | time elapsed: 114.93999290466309s\n",
      "training loss: 0.310 | training accuracy: 86.86%\n",
      "validation loss: 1.081 |  validation accuracy: 59.62%\n",
      "\n",
      "epoch number: 8 | time elapsed: 112.75125670433044s\n",
      "training loss: 0.237 | training accuracy: 90.83%\n",
      "validation loss: 2.086 |  validation accuracy: 39.84%\n",
      "\n",
      "epoch number: 9 | time elapsed: 113.35103583335876s\n",
      "training loss: 0.388 | training accuracy: 83.36%\n",
      "validation loss: 0.904 |  validation accuracy: 64.45%\n",
      "\n",
      "epoch number: 10 | time elapsed: 113.73533701896667s\n",
      "training loss: 0.245 | training accuracy: 90.54%\n",
      "validation loss: 1.177 |  validation accuracy: 57.43%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "best_validation_loss = float('inf')\n",
    "\n",
    "for ep in range(num_epochs):\n",
    "\n",
    "    time_start = time.time()\n",
    "    \n",
    "    training_loss, train_accuracy = train(rnn_model, train_dataloader, optim, loss_func)\n",
    "    validation_loss, validation_accuracy = validate(rnn_model, validation_dataloader, loss_func)\n",
    "    \n",
    "    time_end = time.time()\n",
    "    time_delta = time_end - time_start  \n",
    "    \n",
    "    if validation_loss < best_validation_loss:\n",
    "        best_validation_loss = validation_loss\n",
    "        torch.save(rnn_model.state_dict(), 'rnn_model.pt')\n",
    "    \n",
    "    print(f'epoch number: {ep+1} | time elapsed: {time_delta}s')\n",
    "    print(f'training loss: {training_loss:.3f} | training accuracy: {train_accuracy*100:.2f}%')\n",
    "    print(f'validation loss: {validation_loss:.3f} |  validation accuracy: {validation_accuracy*100:.2f}%')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make predictions using trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_inference(model, sentence):\n",
    "    model.eval()\n",
    "    \n",
    "    # text transformations\n",
    "    sentence = sentence.lower()\n",
    "    sentence = ''.join([c for c in sentence if c not in punctuation])\n",
    "    tokenized = [vocab_to_token.get(token, 0) for token in sentence.split()]\n",
    "    tokenized = np.pad(tokenized, (512-len(tokenized), 0), 'constant')\n",
    "    \n",
    "    # model inference\n",
    "    model_input = torch.LongTensor(tokenized).to(device)\n",
    "    model_input = model_input.unsqueeze(1)\n",
    "    pred = torch.sigmoid(model(model_input))\n",
    "    \n",
    "    return pred.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.021870721131563187\n"
     ]
    }
   ],
   "source": [
    "print(sentiment_inference(rnn_model, \"This film is horrible\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01491193100810051\n"
     ]
    }
   ],
   "source": [
    "print(sentiment_inference(rnn_model, \"Director tried too hard but this film is bad\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.18468593060970306\n"
     ]
    }
   ],
   "source": [
    "print(sentiment_inference(rnn_model, \"Decent movie, although could be shorter\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3845883905887604\n"
     ]
    }
   ],
   "source": [
    "print(sentiment_inference(rnn_model, \"This film will be houseful for weeks\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9387853741645813\n"
     ]
    }
   ],
   "source": [
    "print(sentiment_inference(rnn_model, \"I really loved the movie, every part of it, it was amazing\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
